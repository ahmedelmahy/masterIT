{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of the proposed idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data\n",
    "The dataset I work on is formed of three parts :\n",
    "\n",
    "1. a matrix of normalized gene counts, each row is a human tissue sample and each column is the estimated expression of a specific gene.\n",
    "\n",
    "2. a target array : the target we want to classify e.g. (HER receptor positive vs HER receptor negative ) or (tumor stage early vs late) or (subtype of tumor e.g. ductal or papillary or metastatic), etc. It can either be binary or multiclass. It can also be numeric e.g. age before death (survival)\n",
    "\n",
    "3. an array of the gene names (the column names of matrix mentioned in 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "a = np.load('data/BRCA_HER2_status_data.npy').transpose()\n",
    "labels = np.load('data/BRCA_HER2_status_class.npy')\n",
    "gene_names = np.load('data/BRCA_HER2_status_genes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>60473</th>\n",
       "      <th>60474</th>\n",
       "      <th>60475</th>\n",
       "      <th>60476</th>\n",
       "      <th>60477</th>\n",
       "      <th>60478</th>\n",
       "      <th>60479</th>\n",
       "      <th>60480</th>\n",
       "      <th>60481</th>\n",
       "      <th>60482</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.636884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.070119</td>\n",
       "      <td>3.909544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007719</td>\n",
       "      <td>7.948489</td>\n",
       "      <td>0.073201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129877</td>\n",
       "      <td>3.370021</td>\n",
       "      <td>0.208246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306455</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032339</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>1.782667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.926196</td>\n",
       "      <td>3.540072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029193</td>\n",
       "      <td>6.887261</td>\n",
       "      <td>0.322512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.988904</td>\n",
       "      <td>0.180730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.709098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.031695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.513331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.643069</td>\n",
       "      <td>3.525534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112598</td>\n",
       "      <td>7.534212</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147026</td>\n",
       "      <td>0.151939</td>\n",
       "      <td>3.831975</td>\n",
       "      <td>0.231874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412883</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.067434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.942403</td>\n",
       "      <td>3.560276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135735</td>\n",
       "      <td>7.743208</td>\n",
       "      <td>0.271353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062719</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.124921</td>\n",
       "      <td>0.129128</td>\n",
       "      <td>4.067203</td>\n",
       "      <td>0.261164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519763</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>2.051959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.215758</td>\n",
       "      <td>3.365744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257722</td>\n",
       "      <td>6.970411</td>\n",
       "      <td>0.062656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158857</td>\n",
       "      <td>0.056815</td>\n",
       "      <td>4.425612</td>\n",
       "      <td>0.167314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571092</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60483 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2      3         4         5      6         7      \\\n",
       "0  0.079321  0.000000  1.636884    0.0  2.070119  3.909544    0.0  0.007719   \n",
       "1  0.032339  0.004531  1.782667    0.0  1.926196  3.540072    0.0  0.029193   \n",
       "2  0.031695  0.000000  1.513331    0.0  1.643069  3.525534    0.0  0.112598   \n",
       "3  0.000000  0.000000  2.067434    0.0  1.942403  3.560276    0.0  0.135735   \n",
       "4  0.000000  0.019170  2.051959    0.0  2.215758  3.365744    0.0  0.257722   \n",
       "\n",
       "      8         9      ...    60473     60474     60475     60476     60477  \\\n",
       "0  7.948489  0.073201  ...      0.0  0.089308  0.000000  0.000000  0.129877   \n",
       "1  6.887261  0.322512  ...      0.0  0.007371  0.000000  0.285674  0.000000   \n",
       "2  7.534212  0.057845  ...      0.0  0.157620  0.000000  0.147026  0.151939   \n",
       "3  7.743208  0.271353  ...      0.0  0.062719  0.021173  0.124921  0.129128   \n",
       "4  6.970411  0.062656  ...      0.0  0.046387  0.000000  0.158857  0.056815   \n",
       "\n",
       "      60478     60479  60480     60481  60482  \n",
       "0  3.370021  0.208246    0.0  0.306455    0.0  \n",
       "1  3.988904  0.180730    0.0  0.709098    0.0  \n",
       "2  3.831975  0.231874    0.0  0.412883    0.0  \n",
       "3  4.067203  0.261164    0.0  0.519763    0.0  \n",
       "4  4.425612  0.167314    0.0  0.571092    0.0  \n",
       "\n",
       "[5 rows x 60483 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. example matrix\n",
    "pd.DataFrame(a).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int32), 767)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. example target classes : already preprocessed in a separte file to 0 and 1 , check the log file for the names refered to by 0s and 1s\n",
    "\n",
    "labels[1:10], len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['ENSG00000270112.3', 'ENSG00000167578.15', 'ENSG00000273842.1',\n",
       "        'ENSG00000078237.5', 'ENSG00000146083.10', 'ENSG00000225275.4',\n",
       "        'ENSG00000158486.12', 'ENSG00000198242.12', 'ENSG00000259883.1'],\n",
       "       dtype=object), 60483)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gene names\n",
    "gene_names[1:10], len(gene_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous research\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most previous studies, deal with each dataset separately. This poses many problems since the dataset is usually small, this leads to overfitting and losing much information in dimension reduction. Below are some examples :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this study (Wenric, Stephane, and Ruhollah Shemirani. \"Using supervised learning methods for gene selection in RNA-Seq case-control studies.\" Frontiers in genetics 9 (2018).)\n",
    "The filter the genes using three methods : (differential expression and RF and extreme pseudosamples ) and use the output selected genes in the prediction model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/prev1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this paper (Torres, Rodrigo, et al. \"A machine-learning classifier trained with microRNA ratios to distinguish melanomas from nevi.\" bioRxiv (2018): 507400.): \n",
    "\n",
    "They use a specified version of random forest for feature selection called Boruta and then apply apply a RF model on the selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/bruta.png\", width = 800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this paper (Jabeen, Almas, Nadeem Ahmad, and Khalid Raza. \"Machine learning-based state-of-the-art methods for the classification of RNA-seq data.\" Classification in BioApps. Springer, Cham, 2018. 133-172.):\n",
    "\n",
    "They summarize the machine learning applications on gene expression data and describes in the following image the traditional workflow for modelling gene expression data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/traditional.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem specification\n",
    "\n",
    "The problem with the above/ traditional modelling is that is uses each dataset separately from previous knowledge ignoring a priori knowledge and dealing with each dataset as a new problem. There are many problems with this approach such as :\n",
    "\n",
    "1. It's very hard and inaccurate to train ML models on very small datasets (the usual case in gene expression data due to the high cost of data collection)\n",
    "\n",
    "2. With every filtering step, we compromise to reduce dimentionality but at the cost of losing information. For example, univariate filters, run a correlation test between each feature and the target and filter features with low correlation, but what if two features are both weak predictors but if combined they become a strong predictor and what if one feature is specific to one class but not sensitive (e.g. a gene that is rarely expression, but when it exists it means 100% a tumor, unfortunately, it will be filtered if we filter low expressed genes before modelling).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed solution\n",
    "\n",
    "\n",
    "One common a priori information is that genes (features used for classification) are the same for all datasets, Even if datasets from different experiments or generated by different machines are incomparable, we still can learn common patterns from several datasets, that improves modelling of new datasets.\n",
    "\n",
    "We propose a transfer learning approach to build small NNs with subsets of genes that can be trained on several datasets and learns more information from each dataset they get trained on. The benifits of this approach are as following :\n",
    "\n",
    "1. It will make use of a priori information which hopefully may improve prediction accuracy and generalization\n",
    "\n",
    "2. Each small NN, might be specific for a biological pathway which is very important in science and biology. For example, we might discover a NN with 10 genes that work together very well. If these 10 genes are already known to work together, that is fine, but if this information is new, this might lead to discovering a new biological machanism behind cancer or the disease we were trying to predict. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonDa",
   "language": "python",
   "name": "pythonda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
